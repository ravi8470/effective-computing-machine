# web-scrapper-node

A simple node.js app to recursively crawl web pages for links and store them in the database along with some additional info.

# Tech/framework used

1. node.js
2. mongodb

# Installation

1. git clone 
2. cd to root directory
3. npm i
4. npm start

# How to use?

1. Just start the project with npm start and it will keep crawling until it does not find any more links.